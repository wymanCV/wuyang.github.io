<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Wuyang Li </title>

  <meta name="author" content="Wuyang Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Wuyang Li</name>
                  </p>
                  <p> Currently, I am a third-year Ph.D. candidate (2020~Present) at <a
                      href="http://www.ee.cityu.edu.hk/~yxyuan/">AIM Group</a> of City University of Hong Kong (CityU),
                    supervised by <a href="http://www.cityu.edu.hk/stfprofile/yixuyuan.htm">Prof. Yixuan Yuan</a>. I am
                    broadly interested in computer vision, machine learning, and graph-based learning. My current
                    research focuses on object detection under cross-domain and open-set settings. Before that, I
                    obtained the bachelor's degree in Tianjin University (TJU).
                  </p>

                  <p>[Pined]
                    I have established a team and am working on an LLM-related entrepreneurial project. The focus of my
                    continuing work will also gradually shift from academic tasks to applied projects and marketing. If
                    you are
                    interested, welcome to contact me by email. </li>
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:wuyangli2-c@my.cityu.edu.hk">Email</a> &nbsp/&nbsp
                    <!--                <a href="">CV</a> &nbsp/&nbsp-->
                    <!--                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp-->
                    <a href="https://scholar.google.com/citations?user=3Ml_EbAAAAAJ&hl=zh-CN&oi=ao">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/wymanCV">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/wuyang2.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/wuyang2.jpg" class="hoverZoomLink"></a>




                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>News</heading>
                  <ul>
                    <li>[Apr 2023] One paper accepted by TNNLS</li>
                    <li>[Feb 2023] One paper accepted by CVPR 2023</li>
                    <li>[Jan 2023] One paper accepted by TPAMI</li>
                    <li>[Oct 2022] One paper accepted by TMM</li>
                    <li>[June 2022] SIGMA appears on <font color="red"><strong>CVPR Best Paper Finalist
                          [33/8161]</strong></font>
                    </li>
                    <li>[May 2022] One paper accepted by MICCAI 2022 (<font color="red"><strong>Early Accept,
                          ORAL</strong></font>)</li>
                    <li>[Mar 2022] Two papers accepted by CVPR 2022 (one <font color="red"><strong>ORAL</strong></font>)
                    </li>
                    <li>[Dec 2021] One paper accepted by AAAI 2022 (<font color="red"><strong>ORAL</strong></font>)</li>
                    <li>[Jul 2021] I passed Ph.D. Qualify Examination</li>
                    <li>[Jun 2021] One paper accepted by TIP</li>
                    <!-- <li>[Jun 2021] One paper accepted by EndoCV 2021 in conjunction with ISBI 2021</li> -->
                    <!-- <li>[Mar 2021] 1<sup>st</sup> place for polyp detection task in Endoscopy Computer Vision Challenge (EndoCV 2021)</li> -->
                  </ul>

                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Conference Papers</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="three">
                    <img src='images/anna.png' width="250">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a
                    href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_Adjustment_and_Alignment_for_Unbiased_Open_Set_Domain_Adaptation_CVPR_2023_paper.html">
                    <papertitle> Adjustment and Alignment for Unbiased Open Set Domain Adaptation
                    </papertitle>
                  </a>
                  <br>
                  <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2023
                  <br>
                  <strong>Wuyang Li</strong>, Jie Liu, Bo Han, Yixuan Yuan
                  <br>
                  <!-- <a>paper</a>/ -->
                  <!-- <a>code</a> -->
                  <a
                    href="https://openaccess.thecvf.com/content/CVPR2023/html/Li_Adjustment_and_Alignment_for_Unbiased_Open_Set_Domain_Adaptation_CVPR_2023_paper.html">paper</a>
                  /
                  <a href="https://github.com/CityU-AIM-Group/Anna">codes</a>/
                  <a href="https://www.youtube.com/watch?v=hFZn16ntyXw">Video Presentation</a>
                  <p><em>Key Words</em>: Open Set Domain Adaptation, Causal Theory</p>
                  <p><em>Summary</em>: We treated each image with base-class and novel-class regions and addresee the
                    biased learning in the source domain and biased cross-domain transfer with causal theory.
                  </p>
                </td>
              </tr>


              <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="three">
                    <img src='images/sigma.png' width="250">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://arxiv.org/abs/2203.06398">
                    <papertitle>SIGMA: Semantic-complete Graph Matching for Domain Adaptive Object Detection
                    </papertitle>
                  </a>
                  <br>
                  <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022, <font color="red">
                    <strong>ORAL, Best Paper Finalist</strong>
                  </font>
                  <br>
                  <strong>Wuyang Li</strong>, Xinyu Liu, Yixuan Yuan
                  <br>
                  <a href="https://arxiv.org/pdf/2203.06398.pdf">paper</a> /
                  <a href="https://github.com/CityU-AIM-Group/SIGMA">codes</a> /
                  <a href="https://zhuanlan.zhihu.com/p/492956292">Áü•‰πé</a>
                  <p><em>Key Words</em>: Domain Adaptive Object Detection, Graph-based Learning</p>
                  <p><em>Summary</em>: We proposed a SemantIc-complete Graph MAtching (SIGMA) framework to address the
                    cross-domain semantic-mismatching with fine-grained domain adaptation.</p>
                </td>
              </tr>


              <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="three">
                    <img src='images/NLTE.png' width="250">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">

                  <a href="https://arxiv.org/abs/2204.02620">
                    <papertitle>Towards Robust Adaptive Object Detection under Noisy Annotations</papertitle>
                  </a>
                  <br>
                  <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022
                  <br>
                  Xinyu Liu, <strong>Wuyang Li</strong>, Qiushi Yang, Baopu Li, Yixuan Yuan
                  <br>
                  <a href="https://arxiv.org/abs/2204.02620">paper</a> /
                  <a href="https://github.com/CityU-AIM-Group/NLTE">codes</a>
                  <!--              <p>IEEE Conference on Computer Vision and Pattern Recognition (CVPR 22)</p>-->
                  <p><em>Key Words</em>: Domain adaptive Object Detection, Noisy Label</p>
                  <p><em>Summary</em>: We explored the robust adaptive object detection under noisy annotations and
                    proposed a Noise Latent Transferability Exploration (NLTE) framework to address the issue.</p>
                </td>
              </tr>


              <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="three">
                    <img src='images/FedInI.jpeg' width="250">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://link.springer.com/content/pdf/10.1007/978-3-031-16452-1_30.pdf?pdf=inline%20link">
                    <papertitle>Intervention & Interaction Federated Abnormality Detection with Noisy Clients
                    </papertitle>
                  </a>
                  <br>
                  <em>Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2022, <font color="red">
                    <strong>ORAL, Early Accept</strong>
                  </font>
                  <br>
                  Xinyu Liu, <strong>Wuyang Li</strong>, Yixuan Yuan
                  <br>
                  <a
                    href="https://link.springer.com/content/pdf/10.1007/978-3-031-16452-1_30.pdf?pdf=inline%20link">paper</a>
                  /
                  <a href="https://github.com/CityU-AIM-Group/FedInI">codes</a>
                  <p><em>Key Words</em>: Federated Learning, Noisy Label, Causal Intervention</p>
                  <p><em>Summary</em>: We explored the recognition bias in federated object detection under noisy
                    annotations and proposed a Intervention & Interaction FL framework (FedInI) to address the issue.
                  </p>
                </td>
              </tr>



              <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="three">
                    <img src='images/scan.png' width="250">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a href="https://www.aaai.org/AAAI22Papers/AAAI-902.LiW.pdf">
                    <papertitle>SCAN: Cross Domain Object Detection with Semantic Conditioned Adaptation</papertitle>
                  </a>
                  <br>
                  <em>The Association for the Advance of Artificial Intelligence (AAAI)</em>, 2022, <font color="red">
                    <strong>ORAL</strong>
                  </font>
                  <br>
                  <strong>Wuyang Li</strong>, Xinyu Liu, Xiwen Yao, Yixuan Yuan
                  <br>
                  <a href="https://www.aaai.org/AAAI22Papers/AAAI-902.LiW.pdf">paper</a> /
                  <a href="https://github.com/CityU-AIM-Group/SCAN">codes</a>
                  <!--              <p>The AAAI Conference on Artificial Intelligence (AAAI 2022) <font color="red"><strong>(ORAL)</strong></font></p>-->
                  <p><em>Key Words</em>: Domain adaptive Object Detection, Graph-based Learning</p>
                  <p><em>Summary</em>: We proposed a Semantic Conditioned AdaptatioN (SCAN) framework to address the
                    sub-optimal categorical alignment for domain adaptive object detection.</p>
                </td>
              </tr>

              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                      <heading>Journal Papers</heading>
                    </td>
                  </tr>
                </tbody>
              </table>

              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>

                  <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <div class="three">
                        <img src='images/DUT.png' width="250">
                      </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://ieeexplore.ieee.org/document/10132405">
                        <papertitle>Decoupled Unbiased Teacher for Source-Free Domain Adaptive Medical Object Detection
                        </papertitle>
                      </a>
                      <br>
                      <em>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</em>, 2023, IF: 14.2
                      <br>
                      Xinyu Liu, <strong>Wuyang Li</strong>, Yixuan Yuan
                      <br>
                      <a href="https://ieeexplore.ieee.org/document/10132405">paper</a> /
                      <a href="https://github.com/CUHK-AIM-Group/Decoupled-Unbiased-Teacher">codes</a>
                      <!-- <a href="https://zhuanlan.zhihu.com/p/492956292">Áü•‰πé</a> -->
                      <p><em>Key Words</em>: Source-free Domain Adaptive Object Detection, Causal Theory</p>
                      <p><em>Summary</em>: We leveraged causal theory to explore the bias problem in SFDA, and addressed
                        the sample bias, feature bias, and prediction bias.
                      </p>
                    </td>



                  <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <div class="three">
                        <img src='images/sigma_plus_plus.png' width="250">
                      </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://ieeexplore.ieee.org/document/10012542">
                        <papertitle>SIGMA++: Improved Semantic-complete Graph Matching for Domain Adaptive Object
                          Detection
                        </papertitle>
                      </a>
                      <br>
                      <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>, 2023, IF: 24.314
                      <br>
                      <strong>Wuyang Li</strong>, Xinyu Liu, Yixuan Yuan
                      <br>
                      <a href="https://ieeexplore.ieee.org/document/10012542">paper</a> /
                      <a href="https://github.com/CityU-AIM-Group/SIGMA/tree/SIGMA++">codes</a>
                      <!-- <a href="https://zhuanlan.zhihu.com/p/492956292">Áü•‰πé</a> -->
                      <p><em>Key Words</em>: Domain Adaptive Object Detection, Hypergraph-based Learning</p>
                      <p><em>Summary</em>: We proposed an improved graph-matching framework
                        with
                        hypergraph, addressing the cross-domain semantic-mismatching with fine-grained domain
                        adaptation.
                      </p>
                    </td>

                  <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <div class="three">
                        <img src='images/SCANv2.png' width="250">
                      </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://ieeexplore.ieee.org/document/9931144">
                        <papertitle>SCAN++: Enhanced Semantic Conditioned Adaptation for Domain Adaptive Object
                          Detection
                        </papertitle>
                      </a>
                      <br>
                      <em>IEEE Transactions on Multimedia (TMM)</em>, 2022, IF: 8.182
                      <br>
                      <strong>Wuyang Li</strong>, Xinyu Liu, Yixuan Yuan
                      <br>
                      <a href="https://ieeexplore.ieee.org/document/9931144">paper</a> /
                      <a href="https://github.com/CityU-AIM-Group/SCAN/tree/SCAN++">codes</a>
                      <p><em>Key Words</em>: Domain Adaptive Object Detection</p>
                      <p><em>Summary</em>: We proposed an enhanced semantic-condtioned framework to
                        address the sub-optimal categorical alignment for domain adaptive object detection.</p>
                    </td>
                  </tr>

                  <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <div class="three">
                        <img src='images/htd.jpg' width="250">
                      </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9615001">
                        <papertitle>HTD: Heterogeneous Task Decoupling for Two-Stage Object Detection</papertitle>
                      </a>
                      <br>
                      <em>IEEE Transactions on Image Processing (TIP)</em>, 2022, IF: 11.041
                      <br>
                      <strong>Wuyang Li</strong>, Zhen Chen, Baopu Li, Dingwen Zhang, Yixuan Yuan
                      <br>
                      <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9615001">paper</a> /
                      <a href="https://github.com/CityU-AIM-Group/HTD">codes</a>
                      <!--              <p>IEEE Transactions on Image Processing (TIP 2021), IF: 10.856</p>-->
                      <p><em>Key Words</em>: Generic Object Detection, Graph-based Learning</p>
                      <p><em>Summary</em>: We proposed a Heterogeneous Task Decoupling (HTD) framework to disentangle
                        the
                        sibling head with Graph Convolutional Network and Convolutional Network of two-stage
                        detection pipeline .</p>
                    </td>
                  </tr>



                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                          <heading>Selected Honors</heading>
                          <ul>

                            <li>[2022] Outstanding Academic Performance Award (OAPA), CityU </li>
                            <li>[2022] Research Tuition Scholarship (RTS), CityU </li>
                            <li> [2018] National Scholarship (Top 2% student) </li>
                            <li> [2017] National Scholarship (Top 2% student) </li>
                            <li> [2017-2020] Outstanding Student Scholarship (Top 10% student) </li>
                            <li> [2017] Tianjin Mathematical Competition (Second Prize) </li>
                          </ul>
                        </td>
                      </tr>
                    </tbody>
                  </table>




                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                          <heading>Education</heading>
                        </td>
                      </tr>
                    </tbody>
                  </table>
                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">

                        <td style="padding:40px;width:1%;vertical-align:middle">
                          <div class="three">

                            <img src='images/tju.png' width="100">
                          </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <a href="http://www.tju.edu.cn/english/index.htm">
                            <papertitle>Tianjin University (TJU), China</papertitle>
                          </a>
                          <br>
                          <p>Sep. 2016 - Jun. 2020Ôºö Bachelor's degree of Communication Engineering. </p>
                          <p>GPA: 3.83/4.00, 91.3/100, Ranking 6/120</p>
                        </td>
                      </tr>

                      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">

                        <td style="padding:50px;width:1%;vertical-align:middle">
                          <div class="three">
                            <img src='images/nusri.png' width="80">
                          </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <a href="http://en.nusri.cn/">
                            <papertitle>NUS (Suzhou) Research Institute (NUSRI), China</papertitle>
                          </a>
                          <br>
                          <p>Sep. 2019 - Jun. 2020: Exchanging program of Electrical and Computer Engineering. </p>
                          <p>Supervisors: Prof. Zhiying Zhou</p>
                          <p>Complete the project: Towards Webpage-based Augmentation Reality (AR)</p>
                        </td>
                      </tr>

                      <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">

                        <td style="padding:0px;width:1%;vertical-align:middle">
                          <div class="three">
                            <img src='images/cityu.png' width="180">
                          </div>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                          <a href="https://www.cityu.edu.hk/">
                            <papertitle>City University of Hong Kong (CityU), China</papertitle>
                          </a>
                          <br>
                          <p>Sep. 2020 - present: Ph.D Study of Electrical Engineering. </p>
                          <p>Supervisors: Prof. Yixuan Yuan</p>
                          <!--              <p>Complete the project: Towards Webpage-based Augmentation Reality (AR)</p>-->
                        </td>
                      </tr>




                      <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                          <tr>
                            <td style="padding:20px;width:100%;vertical-align:middle">
                              <heading>Leadership Experience</heading>
                            </td>
                          </tr>
                        </tbody>
                      </table>
                      <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">

                            <td style="padding:10px;width:1%;vertical-align:middle">
                              <div class="three">
                                <img src='images/leader1.png' width="200">
                              </div>
                            </td>
                            <td style="padding:20px;width:75%;vertical-align:middle">
                              <a>
                                <papertitle>Freshman Leader, Tianjin University</papertitle>
                              </a>
                              <br>
                              <p>Jun. 2017 - Jun. 2018: Freshman leader for Class 2, communication engineering </p>
                              <p>I was fortunate to be one of eight freshman leaders selected through the departmet.</p>
                            </td>
                          </tr>

                          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">

                            <td style="padding:60px;width:1%;vertical-align:middle">
                              <div class="three">
                                <img src='images/leader2.jpg' width="100">
                              </div>
                            </td>
                            <td style="padding:20px;width:75%;vertical-align:middle">
                              <a>
                                <papertitle> Student Union Chairman of Electrical and Information Engineering
                                  Department,
                                  Tianjin University</papertitle>
                              </a>
                              <br>
                              <p>Sep. 2018 - Jun. 2020: Chairman of the publicity department. </p>

                              <p> I was fortunate to be selected as the publicity department chairman of the student
                                union
                                in Electrical and Information Engineering Department, Tianjin University. </p>
                              <!--               <p>Supervisors: Prof. Zhiying Zhou</p>-->
                              <!--              <p>Complete the project: Towards Webpage-based Augmentation Reality (AR)</p>-->
                            </td>
                          </tr>






                          <table
                            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                            <tbody>
                              <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                  <heading>Personal Interests</heading>
                                  <ul>
                                    <li> Painting and Desinging: I used to do sketch training with art candidates and
                                      have a
                                      certain level of graphic design foundation. I have a strong interest in user needs
                                      analysis and product design. </li>
                                    <li> I am looking for the opportunity to establish a start-up team and create some
                                      awesome high-tech products.</li>
                                  </ul>
                                </td>
                              </tr>
                            </tbody>
                          </table>






                          <table
                            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                            <tbody>

                              <table
                                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                                <tbody>
                                  <tr>
                                    <td style="padding:0px">
                                      <br>
                                      <a style="text-align:right;font-size:small;">
                                        <a href="https://jonbarron.info/">We steal this website from this guy</a>
                                        </p>
                                    </td>
                                  </tr>
                                </tbody>
                              </table>
        </td>
      </tr>
  </table>
</body>

</html>