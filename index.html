<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Wuyang Li</title>
  
  <meta name="author" content="Wuyang Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Wuyang Li</name>
              </p>
              <p> Currently, I am a second-year Ph.D. student at <a href="http://www.ee.cityu.edu.hk/~yxyuan/">AIM Group</a> of City University of Hong Kong (CityU), supervised by <a href="http://www.cityu.edu.hk/stfprofile/yixuyuan.htm">Prof. Yixuan Yuan</a>. My research interests follow the main stream of Object Detection, and separate into several sub-fields, including Domain Adaptation, Open Set, and Graph-based learning. Before that, I obtained the bachelor's degree in Department of Electrical and Information Engineering of Tianjin University (TJU).
              </p>
<!--              <p>-->

<!--                <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.-->
<!--              </p>-->
              <p style="text-align:center">
                <a href="mailto:wuyangli2-c@my.cityu.edu.hk">Email</a> &nbsp/&nbsp
                <a href="">CV</a> &nbsp/&nbsp
<!--                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp-->
<!--                <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp-->
<!--                <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp-->
                <a href="https://github.com/wymanCV">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/wuyang.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul>
		<li>[June 2022] SIGMA enters <font color="red"><strong>CVPR Best Paper Finalist</strong></font> </li>
		<li>[Mar 2022] One paper accepted by MICCAI 2022.</li>
                <li>[Mar 2022] Two papers accepted by CVPR 2022 (one <font color="red"><strong>ORAL</strong></font>)</li>
                <li>[Dec 2021] One paper accepted by AAAI 2022 (<font color="red"><strong>ORAL</strong></font>)</li>
                <li>[Jul 2021] I passed Ph.D. Qualify Examination</li>
                <li>[Jun 2021] One paper accepted by TIP 2021 <strong>(IF: 10.856)</strong></li>
                <li>[Jun 2021] One paper accepted by EndoCV 2021 in conjunction with ISBI 2021.</li>
                <li>[Mar 2021] 1<sup>st</sup> place for polyp detection task in Endoscopy Computer Vision Challenge (EndoCV 2021)</li>
              </ul>

            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publication</heading>

<!--              <p> My current researchs mainly cover generic object detection, domain adaptative object detection, and graph-based learning.</p>-->
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="three">
                <img src='images/sigma.png' width="250">
              </div>
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">

              <a  href="https://arxiv.org/abs/2203.06398">
                <papertitle>SIGMA: Semantic-complete Graph Matching for Domain Adaptive Object Detection</papertitle>
              </a>
              <br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022, <font color="red"><strong>ORAL, Best Paper Finalist</strong></font></li>
              <br>
              <strong>Wuyang Li</strong>, Xinyu Liu, Yixuan Yuan
              <br>
              	<a href="https://arxiv.org/pdf/2203.06398.pdf">paper</a> /
		<a href="https://github.com/CityU-AIM-Group/SIGMA">codes</a> /
		<a href="https://zhuanlan.zhihu.com/p/492956292">Áü•‰πé</a>
		
<!--              <p>IEEE Conference on Computer Vision and Pattern Recognition (CVPR 22)</p>-->
              <p><em>Area</em>: Domain Adaptative Object Detection, Graph-based Learning</p>
              <p><em>Summary</em>: We proposed a SemantIc-complete Graph MAtching (SIGMA) framework to address the cross-domain semantic-mismatching and achieve fine-grained domain adaptation.</p>
            </td>
          </tr>

          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="three">
                <img src='images/NLTE2.jpg' width="250">
              </div>
            </td>

            <td style="padding:20px;width:75%;vertical-align:middle">

              <a  href="https://arxiv.org/abs/2204.02620">
                <papertitle>Towards Robust Adaptive Object Detection under Noisy Annotations</papertitle>
              </a>
              <br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2022
              <br>
               Xinyu Liu, <strong>Wuyang Li</strong>, Qiushi Yang, Baopu Li, Yixuan Yuan
              <br>
		<a href="https://arxiv.org/abs/2204.02620">paper</a> /
		<a href="https://github.com/CityU-AIM-Group/NLTE">codes</a>
<!--              <p>IEEE Conference on Computer Vision and Pattern Recognition (CVPR 22)</p>-->


              <p><em>Area</em>: Domain Adaptative Object Detection, Noisy Label</p>
              <p><em>Summary</em>: We explored the robust adaptative object detection under noisy annotations and proposed a Noise Latent Transferability Exploration (NLTE) framework to address the issue.</p>
            </td>
          </tr>

          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="three">
                <img src='images/scan3.png' width="250">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
				<a href="https://www.aaai.org/AAAI22Papers/AAAI-902.LiW.pdf">
                <papertitle>SCAN: Cross Domain Object Detection with Semantic Conditioned Adaptation</papertitle>
                </a>
              <br>
              <em>The Association for the Advance of Artificial Intelligence (AAAI)</em>, 2022, <font color="red"><strong>ORAL</strong></font>
              <br>
              <strong>Wuyang Li</strong>, Xinyu Liu, Xiwen Yao, Yixuan Yuan
              <br>
              				<a href="https://www.aaai.org/AAAI22Papers/AAAI-902.LiW.pdf">paper</a> /
							<a href="https://github.com/CityU-AIM-Group/SCAN">codes</a>
<!--              <p>The AAAI Conference on Artificial Intelligence (AAAI 2022) <font color="red"><strong>(ORAL)</strong></font></p>-->
              <p><em>Area</em>: Domain Adaptative Object Detection, Graph-based Learning</p>
              <p><em>Summary</em>: We proposed a Semantic Conditioned AdaptatioN (SCAN) framework to address the sub-optimal categorical alignment for domain adaptative object detection.</p>
            </td>
          </tr>

          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="three">
                <img src='images/htd.jpg' width="250">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
				<a  href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9615001">
                <papertitle>HTD: Heterogeneous Task Decoupling for Two-Stage Object Detection</papertitle>
              </a>
           <br>
              <em>IEEE Transactions on Image Processing (TIP)</em>, 2022, IF: 10.856
              <br>
              <strong>Wuyang Li</strong>, Zhen Chen, Baopu Li, Dingwen Zhang, Yixuan Yuan
              <br>
              				<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9615001">paper</a> /
							<a href="https://github.com/CityU-AIM-Group/HTD">codes</a>
<!--              <p>IEEE Transactions on Image Processing (TIP 2021), IF: 10.856</p>-->
              <p><em>Area</em>: Generic Object Detection, Graph-based Learning</p>
              <p><em>Summary</em>: We proposed a Heterogeneous Task Decoupling (HTD) framework to disentangle the sibling head with Graph Convolutional Network (GCN) and Convolutional Network (CNN) of two-stage detection pipeline .</p>
            </td>
          </tr>


<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <heading>Honors & Scholarships</heading>
      <ul>
        <li> [2018] National Scholarship (Top 2% student) </li>
        <li> [2017] National Scholarship (Top 2% student)  </li>
        <li> [2017-2020] Outstanding Student Scholarship (Top 10% student) </li>
        <li> [2017] Tianjin Mathematical Competition (Second Prize) </li>
      </ul>
    </td>
  </tr>
</tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">

            <td style="padding:40px;width:1%;vertical-align:middle">
              <div class="three">

                <img src='images/tju.png' width="100">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.tju.edu.cn/english/index.htm">
                <papertitle>Tianjin University (TJU), China</papertitle>
              </a>
              <br>
              <p>Sep. 2016 - Jun. 2020Ôºö  Bachelor's degree of Communication Engineering.  </p>
               <p>GPA: 3.83/4.00, 91.3/100, Ranking 6/120</p>
            </td>
          </tr>

          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">

            <td style="padding:50px;width:1%;vertical-align:middle">
              <div class="three">
                <img src='images/nusri.png' width="80">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://en.nusri.cn/">
                <papertitle>NUS (Suzhou) Research Institute (NUSRI), China</papertitle>
              </a>
              <br>
              <p>Sep. 2019 - Jun. 2020: Exchanging program of Electrical and Computer Engineering.  </p>
               <p>Supervisors: Prof. Zhiying Zhou</p>
              <p>Complete the project: Towards Webpage-based Augmentation Reality (AR)</p>
            </td>
          </tr>

          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">

            <td style="padding:0px;width:1%;vertical-align:middle">
              <div class="three">
                <img src='images/cityu.png' width="180">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.cityu.edu.hk/">
                <papertitle>City University of Hong Kong (CityU), China</papertitle>
              </a>
              <br>
              <p>Sep. 2020 - present: Ph.D Study of Electrical Engineering.  </p>
               <p>Supervisors: Prof. Yixuan Yuan</p>
<!--              <p>Complete the project: Towards Webpage-based Augmentation Reality (AR)</p>-->
            </td>
          </tr>




        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Leadership Experience</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">

            <td style="padding:10px;width:1%;vertical-align:middle">
              <div class="three">
                <img src='images/leader1.png' width="200">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a >
                <papertitle>Freshman Leader, Tianjin University</papertitle>
              </a>
              <br>
              <p>Jun. 2017 - Jun. 2018: Freshman leader for Class 2, communication engineering  </p>
               <p>I was fortunate to be one of eight freshman leaders selected through the departmet.</p>
            </td>
          </tr>

          <tr onmouseout="nerfsuper_stop()" onmouseover="nerfsuper_start()">

            <td style="padding:60px;width:1%;vertical-align:middle">
              <div class="three">
                <img src='images/leader2.jpg' width="100">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a >
                <papertitle> Student Union Chairman of Electrical and Information Engineering Department, Tianjin University</papertitle>
              </a>
              <br>
              <p>Sep. 2018 - Jun. 2020: Chairman of the publicity department. </p>

                <p> I was fortunate to be selected as the publicity department chairman of the student union in Electrical and Information Engineering Department, Tianjin University.  </p>
<!--               <p>Supervisors: Prof. Zhiying Zhou</p>-->
<!--              <p>Complete the project: Towards Webpage-based Augmentation Reality (AR)</p>-->
            </td>
          </tr>






<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
    <td style="padding:20px;width:100%;vertical-align:middle">
      <heading>Personal Interests</heading>
      <ul>
        <li> Painting and Desinging: I used to do sketch training with art candidates and have a certain level of graphic design foundation. I have a strong interest in user needs analysis and product design.    </li>
        <li> I am looking for the opportunity to establish a start-up team and create some awesome high-tech products.</li>
      </ul>
    </td>
  </tr>
</tbody></table>






<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <a style="text-align:right;font-size:small;">
                 <a href="https://jonbarron.info/" >We steal this website from this guy</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
